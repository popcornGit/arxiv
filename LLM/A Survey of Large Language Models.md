# 大型语言模型综述全新出炉：从T5到GPT-4最全盘点，国内20余位研究者联合撰写
大型语言模型综述全新出炉：从T5到GPT-4最全盘点，国内20余位研究者联合撰写

自 20 世纪 50 年代图灵测试提出以来，人们始终在探索机器处理语言智能的能力。

语言本质上是一个错综复杂的人类表达系统，受到语法规则的约束。

因此，开发能够理解和精通语言的强大 AI 算法面临着巨大挑战。

过去二十年，语言建模方法被广泛用于语言理解和生成，包括统计语言模型和神经语言模型。

近些年，研究人员通过在大规模语料库上预训练 Transformer 模型产生了预训练语言模型（PLMs），并在解决各类 NLP 任务上展现出了强大的能力。

并且研究人员发现模型缩放可以带来性能提升，因此他们通过将模型规模增大进一步研究缩放的效果。

有趣的是，当参数规模超过一定水平时，这个更大的语言模型实现了显著的性能提升，并出现了小模型中不存在的能力，比如上下文学习。

为了区别于 PLM，这类模型被称为大型语言模型（LLMs）。

从 2019 年的谷歌 T5 到 OpenAI GPT 系列，参数量爆炸的大模型不断涌现。

可以说，LLMs 的研究在学界和业界都得到了很大的推进，尤其去年 11 月底对话大模型 ChatGPT 的出现更是引起了社会各界的广泛关注。

LLMs 的技术进展对整个 AI 社区产生了重要影响，并将彻底改变人们开发和使用 AI 算法的方式。

考虑到 LLMs 的快速技术进步，中国人民大学的二十几位研究者通过背景知识、关键发现和主流技术等三方面回顾了 LLMs 的最新进展，尤其关注 LLMs 的预训练、自适应调优、使用和能力评估。

此外他们还总结和开发 LLMs 的可用资源，讨论了未来发展方向等问题。对于领域内研究人员和工程师而言，这份综述是一份极其有用的学习资源。

![image](https://user-images.githubusercontent.com/48575896/229475367-231b5cfb-f042-4982-8279-94aa61921eb3.png)

论文链接：https://arxiv.org/abs/2303.18223

在进入正文前，我们先来看 2019 年以来出现的各种大语言模型（百亿参数以上）时间轴，其中标黄的大模型已开源。

![image](https://user-images.githubusercontent.com/48575896/229475469-4b5efdee-b155-4ae0-82f1-77f4d8cb3964.png)


# LLMs 概览
在第一节中，研究者详细介绍了 LLMs 的背景、能力和关键技术。

## LLMs 的背景
通常，大型语言模型（LLM）是指包含数千亿（或更多）参数的语言模型，这些参数是在大量文本数据上训练的，例如模型 GPT-3、PaLM、Galactica 和 LLaMA。

具体来说，LLM 建立在 Transformer 架构之上，其中多头注意力层堆叠在一个非常深的神经网络中。

现有的 LLM 主要采用与小语言模型类似的模型架构（即 Transformer）和预训练目标（即语言建模）。

作为主要区别，LLM 在很大程度上扩展了模型大小、预训练数据和总计算量（扩大倍数）。

他们可以更好地理解自然语言，并根据给定的上下文（例如 prompt）生成高质量的文本。

这种容量改进可以用标度律进行部分地描述，其中性能大致遵循模型大小的大幅增加而增加。

然而根据标度律，某些能力（例如，上下文学习）是不可预测的，只有当模型大小超过某个水平时才能观察到。

## LLMs 的涌现能力
LLM 的涌现能力被正式定义为「在小型模型中不存在但在大型模型中出现的能力」，这是 LLM 与以前的 PLM 区分开来的最显著特征之一。

当出现这种新的能力时，它还引入了一个显著的特征：当规模达到一定水平时，性能显著高于随机的状态。

以此类推，这种新模式与物理学中的相变现象密切相关。

原则上，这种能力也可以与一些复杂的任务有关，而人们更关心可以应用于解决多个任务的通用能力。

这里简要介绍了 LLM 的三种代表性的涌现能力：

### 上下文学习。
GPT-3 正式引入了上下文学习能力：假设语言模型已经提供了自然语言指令和多个任务描述，它可以通过完成输入文本的词序列来生成测试实例的预期输出，而无需额外的训练或梯度更新。

### 指令遵循。
通过对自然语言描述（即指令）格式化的多任务数据集的混合进行微调，LLM 在微小的任务上表现良好，这些任务也以指令的形式所描述。

这种能力下，指令调优使 LLM 能够在不使用显式样本的情况下通过理解任务指令来执行新任务，这可以大大提高泛化能力。

### 循序渐进的推理。
对于小语言模型，通常很难解决涉及多个推理步骤的复杂任务，例如数学学科单词问题。

同时，通过思维链推理策略，LLM 可以通过利用涉及中间推理步骤的 prompt 机制来解决此类任务得出最终答案。

据推测，这种能力可能是通过代码训练获得的。

