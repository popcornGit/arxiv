# NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis

## 摘要
我们提出了一种方法，通过使用稀疏的输入视图集优化underlying continuous volumetric scene function函数，实现了最先进的结果，用于合成复杂场景的新视图。

我们的算法使用全连接(非卷积)深度网络表示一个场景，其输入是一个连续的5D坐标(空间位置(x, y, z)和观看方向(θ, φ))，其输出是该空间位置的volume density和view-dependent emitted radiance。

我们通过沿着相机光线querying5D坐标来合成视图，并使用经典的体渲染技术将输出的颜色和密度投影到图像中。

因为体素渲染是自然可微的，所以优化我们的表示所需要的唯一输入是一组具有已知相机位姿的图像。

我们描述了如何有效地优化神经辐射场，以渲染具有复杂几何和外观的场景的逼真的新视图，并演示了优于先前在神经渲染和视图合成方面的工作的结果。

视图合成结果最好作为视频观看，因此我们敦促读者查看我们的补充视频，以便进行令人信服的比较。

## 介绍
  在这项工作中，我们以一种新的方式解决了长期存在的视图合成问题，直接优化连续5D场景表示的参数，以最大限度地减少渲染一组捕获图像的误差。

  我们将静态场景表示为一个连续的5D函数，它输出空间中每个点(x, y, z)在每个方向(θ， φ)上发射的辐射度(radiance emitted)，以及每个点上的密度，就像一个微分不透明度，通过光线经过点(x, y, z)来控制射线累积的辐射度。

我们的方法优化了一个深度全连接神经网络，没有任何卷积层(通常称为多层感知器或MLP)，通过从单个5D坐标(x, y, z， θ， φ)回归到单个体积密度和依赖于视图的RGB颜色来表示这个函数。

为了从特定的视点渲染神经辐射场(NeRF):

1)让摄像机光线穿过场景，生成一组采样的3D点

2)利用上诉3D点及其对应点二维观看方向作为神经网络的输入，以产生一组颜色和密度的输出，

3)使用经典的体素渲染技术将这些颜色和密度累积到2D图像中。

因为这个过程是自然可微的，我们可以使用梯度下降来优化这个模型，通过最小化每个观察到的图像和我们的表示所呈现的相应视图之间的误差。

通过将高体素密度和精确的颜色分配到包含真实底层场景内容的位置，最小化跨多个视图的这种误差，鼓励网络预测场景的一致模型。

![image](https://user-images.githubusercontent.com/48575896/226281916-bd1ed524-08e5-4d9e-b248-475d5ea34849.png)

  我们发现，优化复杂场景的神经辐射场representation的经典实现不会收敛到足够高的分辨率表示，并且在每个相机光线所需的样本数量方面效率低下。

我们通过使用位置编码转换输入5D坐标来解决这些问题，该编码使MLP能够表示更高频率的函数，并且我们提出了一种分层采样过程，以减少对这种高频场景表示进行充分采样所需的查询数量。

  我们的方法继承了体素表示的优点:两者都可以表示复杂的现实世界的几何和外观，并且非常适合使用投影图像进行基于梯度的优化。

至关重要的是，我们的方法克服了离散体素网格在高分辨率建模复杂场景时令人望而却步的存储成本。

综上所述，我们的技术贡献有:

  一种将具有复杂几何和材料的连续场景表示为5D神经辐射场的方法，参数化为基本MLP网络。
  
  一个基于经典体素渲染技术的可微分渲染过程，我们用它来优化标准RGB图像的representations。这包括一个分层抽样策略，将MLP的容量分配给具有可见场景内容的空间。
  
  将每个输入5D坐标映射到高维空间的位置编码，使我们能够成功优化神经辐射场来表示高频场景内容。
  
我们证明，我们得到的神经辐射场方法在定量和定性上优于最先进的视图合成方法，包括将神经3D表示适合场景的工作，以及训练深度卷积网络来预测采样的体积表示的工作。

据我们所知，本文提出了第一个连续神经场景表示，能够从自然环境中捕获的RGB图像中渲染真实物体和场景的高分辨率逼真新视图。

## Neural Radiance Field Scene Representation
我们将连续场景表示为5D向量值函数，其输入是3D位置x = (x, y, z)和2D观看方向(θ， φ)，其输出是发射颜色c = (r, g, b)和体积密度σ。

在实践中，我们用三维笛卡尔单位向量d来表示方向。

我们用MLP网络FΘ:(x, d)→(c， σ)近似这种连续5D场景表示，并优化其权重Θ以将每个输入5D坐标映射到其相应的体积密度和定向发射颜色。

通过限制网络预测体积密度σ仅作为位置x的函数，同时允许RGB颜色c作为位置和观看方向的函数来预测，我们鼓励representation是多视图一致的。

为了实现这一点，MLP FΘ首先处理输入三维坐标x与8个全连接层(使用ReLU激活和每层256通道)，并输出σ和256维特征向量。

然后，该特征向量与摄像机光线的观看方向连接，并传递到一个额外的全连接层(使用ReLU激活和128个通道)，该层输出依赖于视图的RGB颜色。

图3是我们的方法如何使用输入观察方向来表示非兰伯效应的例子。如图4所示，一个没有视图依赖的训练模型(只有x作为输入)很难表示镜面。

## Volume Rendering with Radiance Fields
我们的5D神经辐射场表示空间中任意点的体素密度和定向发射辐射的场景。

我们使用经典体渲染[16]的原理来渲染任何穿过场景的光线的颜色。

体素密度σ(x)可以解释为射线在x位置上终止于无限小粒子的微分概率。

期望的颜色具有远近界tn和tf的相机射线r(t) = o + td的C(r)为:

![image](https://user-images.githubusercontent.com/48575896/226292231-a0fc6447-a8b3-4307-b186-d37323781d4f.png)

函数T(t)表示沿射线从tn到T的累计透过率，即，射线从tn到T而不撞击任何其他粒子的概率。

从我们的连续神经辐射场渲染视图需要估计通过所需虚拟相机的每个像素跟踪的相机光线的积分C(r)。

我们用积分法对这个连续积分进行了数值估计。

确定性正交，通常用于呈现离散体素网格，将有效地限制我们表示的分辨率，因为MLP只会在固定的离散位置集上查询。

相反，我们使用分层抽样方法，将[tn, tf]划分为N个均匀间隔的容器，然后从每个容器中均匀随机地抽取一个样本:
