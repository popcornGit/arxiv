# Block-NeRF: Scalable Large Scene Neural View Synthesis

## Abstract
我们提出了Block-NeRF，神经辐射的变体可以表示大规模环境。

具体来说，我们演示了在缩放NeRF以渲染跨越多个街区的城市规模场景时，将场景分解为单独训练的NeRF是至关重要的。

这种分解将渲染时间与场景大小分离，使渲染能够扩展到任意大的环境，并允许对环境的每个块进行更新。

我们采用了几项架构更改，使NeRF对不同环境条件下几个月捕获的数据具有健壮性。

我们为每个单独的NeRF添加了appearance embeddings、 learned pose refinement和可控曝光，并引入了在相邻NeRF之间对齐外观的过程，以便它们可以无缝组合。

我们从280万张图像中构建了一个block - nerf网格，以创建迄今为止最大的神经场景表示，能够渲染整个旧金山社区。

## Introduction
神经渲染方面的最新进展，如神经辐射场[42]，已经能够在给定一组相机图像的情况下实现照片逼真重建和新颖的视图合成[3,40,45]。

早期的工作侧重于小规模和以对象为中心的重建。

虽然现在有些方法可以解决单个房间或建筑物大小的场景，但这些方法通常仍然是有限的，不能完全扩展到城市规模的环境。

由于模型容量有限，将这些方法应用于大型环境通常会导致远古效果和较低的视觉保真度。

重构大规模环境可以在自动驾驶[32,44,68]和航空测量[14,35]等领域实现几个重要的用例。一个例子是建图，其中创建了整个操作域的高保真地图，作为各种问题的强大先验，包括机器人定位、导航和避免碰撞。

此外，大规模场景重建可用于闭环机器人仿真[13]。

自动驾驶系统通常通过重新模拟之前遇到的场景来评估;然而，任何偏离记录的遭遇都可能改变车辆的轨迹，需要沿着改变的路径绘制高保真的新视图。

除了基本的视图合成外，基于场景的nerf还能够改变环境照明条件，如相机曝光、天气或一天中的时间，这可用于进一步增强模拟场景。

重建如此大规模的环境带来了额外的挑战，包括瞬态对象(汽车和行人)的存在，模型容量的限制，以及内存和计算的限制。

此外，在一致的条件下，在一次捕获中收集如此大环境的训练数据是极不可能的。

相反，环境不同部分的数据可能需要来自不同的数据收集工作，在场景几何(例如，建筑工作和停放的汽车)和外观(例如，天气条件和一天的时间)中引入差异。

我们用appearance embeddings和learned pose refinement来扩展NeRF，以解决收集数据中的环境变化和姿态误差。

我们还添加了曝光调节，以提供在推断过程中修改曝光的能力。

我们将这个修正模型称为Block-NeRF。

扩大Block-NeRF的网络容量使其能够表示越来越大的场景。

然而，这种方法也有一些局限性;随着网络的大小呈现耗时增加，网络不再适合单个计算设备，更新或扩展环境需要重新训练整个网络。

为了解决这些挑战，我们建议将大型环境划分为单独训练的block - nerf，然后在推理时动态呈现和组合。

独立地对这些block - nerf建模允许最大的灵活性，可以扩展到任意大的环境，并提供以分段方式更新或引入新区域的能力，而无需重新训练整个环境，如图1所示。

为了计算目标视图，只渲染block - nerf的一个子集，然后根据它们相对于相机的地理位置进行合成。

为了实现更无缝的合成，我们提出了一种外观匹配技术，通过优化不同block - nerf的外观嵌入，将其带入视觉对齐。

## Background
我们建立在NeRF[42]和它的扩展mip-NeRF[3]。

在此，我们对这些方法的相关部分进行总结, 详情请参阅论文原文。

### NeRF and mip-NeRF Preliminaries
神经辐射场(NeRF)[42]是一种基于坐标的神经场景表示，它通过可微分渲染损失进行优化，以重现一组来自已知相机姿势的输入图像的外观。

优化后，NeRF模型可以用来渲染以前未见过的视点。

NeRF场景表示是一对多层感知器(mlp)。第一个MLP fσ取三维位置x，输出体积密度σ和特征向量。

该特征向量与2D观看方向d连接，馈送到第二个MLP fc，输出RGB颜色c。

这种架构确保输出颜色可以在从不同角度观察时发生变化，允许NeRF表示反射和光滑材料，但σ表示的底层几何仅是位置的函数。

图像中的每个像素在三维空间中对应一条射线r(t) = o + td。

为了计算r的颜色，NeRF沿射线随机采样距离![image](https://user-images.githubusercontent.com/48575896/226497140-ba58548c-4396-4129-a91a-ccd5614fc3ff.png)，通过点r(ti)和方向d通过它的mlp进行计算![image](https://user-images.githubusercontent.com/48575896/226497182-df89ce72-cea7-4a46-9a7e-1713e9ac22bf.png)

结果输出颜色为:
![image](https://user-images.githubusercontent.com/48575896/226497210-cfe4d2a2-4b76-4b27-9d9c-b9a87fadddb2.png)

完整的NeRF实现迭代地重新采样点ti(通过将权重wi视为概率分布)，以便更好地将样本集中在高密度区域。

为了使NeRF mlp能够表示更高的频率细节[63]，输入x和d分别经过分量正弦位置编码γPE预处理:

![image](https://user-images.githubusercontent.com/48575896/226497592-1691931c-12b8-4979-a256-4abb55be7c9f.png)

其中L是位置编码的层数。

NeRF的MLP fσ以单个3D点作为输入.

然而，这忽略了相应图像像素的相对占地面积和间隔[ti−1,ti]沿着包含点的射线r，导致在渲染新相机轨迹时产生混叠工件。

MipNeRF[3]通过使用投影像素足迹沿着射线而不是间隔对锥形截锥进行采样来解决这个问题。

![image](https://user-images.githubusercontent.com/48575896/226497948-fc73dd71-218c-42f1-9055-ed5fec0b78ab.png)

为了将这些截锥送入MLP, mip-NeRF将它们近似为带有参数µi， Σi的高斯分布，并将位置编码γPE替换为其在输入高斯上的期望，称为集成位置编码。

## Method
