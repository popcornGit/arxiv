# Segment Anything
# Abstract
我们介绍了Segment Anything (SA)项目:一个用于图像分割的新任务、模型和数据集。

在数据收集循环中使用我们的高效模型，我们构建了迄今为止(到目前为止)最大的分割数据集，在11M张授权和隐私尊重的图像上拥有超过10亿个掩码。

该模型被设计和训练为可提示的，因此它可以zero-shot转移到新的图像分布和任务。

我们评估了它在许多任务上的能力，发现它的zero-shot表现令人印象深刻, 经常与之前的完全监督结果竞争，甚至更好。

我们在上发布了1B掩模和11M图像的片段任意模型(SAM)和对应数据集(SA-1B)，以促进对计算机视觉基础模型的研究。https://segment-anything.com

# Introduction
在网络规模的数据集上预训练的大型语言模型正在以强大的零次和少次泛化彻底改变NLP.

这些“基础模型”可以泛化到训练过程中看不到的任务和数据分布。

这种功能通常通过提示工程实现，在提示工程中，使用手工制作的文本提示语言模型为手头的任务生成有效的文本响应。

当使用来自网络的丰富文本语料库进行缩放和训练时，这些模型的零镜头和少镜头性能与微调模型(在某些情况下甚至匹配)相比惊人地好。

经验趋势表明，这种行为随着模型规模、数据集大小和总训练计算而改善.

基础模型也在计算机视觉中进行了探索，尽管程度较轻。

也许最突出的插图是对齐来自网络的配对文本和图像。

例如，CLIP[82]和ALIGN[55]使用对比学习来训练对齐两种模式的文本和图像编码器。

经过训练后，经过设计的文本提示可以实现对新颖视觉概念和数据分布的零概率泛化。

这样的编码器还可以有效地与其他模块组合以实现下游任务，例如图像生成(例如DALL·E[83])。

虽然在视觉和语言编码器方面已经取得了很大的进展，但计算机视觉包括了超出这一范围的广泛问题，并且对于其中许多问题，不存在丰富的训练数据。

在这项工作中，我们的目标是建立一个图像分割的基础模型。

也就是说，我们试图开发一个prompt-able模型，并使用一种能够实现强大泛化的任务在广泛的数据集上对其进行预训练。

有了这个模型，我们的目标是用快速工程解决一系列新的数据分布上的下游分割问题。

该计划的成功取决于三个组成部分:任务、模型和数据。

为了开发它们，我们解决了以下关于图像分割的问题:

1. 什么任务可以实现zero-shot泛化?

2. 相应的模型架构是什么?

3. 哪些数据可以支持这个任务和模型?

这些问题错综复杂，需要综合解决。

我们首先定义一个可提示的分割任务，该任务足够普遍，可以提供一个强大的预训练目标，并支持广泛的下游应用。

这项任务需要一个模型，支持灵活的提示，并可以输出分割掩码实时提示时，允许交互式使用。

为了训练我们的模型，我们需要一个多样化的、大规模的数据源。

不幸的是，目前还没有用于分割的网络级数据源;为了解决这个问题，我们构建了一个“数据引擎”，即在使用我们的高效模型来辅助数据收集和使用新收集的数据来改进模型之间进行迭代。

接下来，我们将介绍每个相互连接的组件，然后是我们创建的数据集和证明我们方法有效性的实验。

## Task
在NLP和最近的计算机视觉中，基础模型是一个有前途的发展，它可以通过使用“提示”技术对新数据集和任务执行零次和少次学习。

受此工作的启发，我们提出了可提示的分割任务，其目标是给定任何分割提示，返回有效的分割掩码(见图1a)。

![image](https://user-images.githubusercontent.com/48575896/230816775-68936e78-d89c-4db4-adac-a3625e32dcee.png)

一个Prompt简单地指定在图像中分割什么，例如，提示符可以包括空间或文本信息标识一个对象。

有效输出掩码的要求意味着，即使提示符是模糊的，并且可能指向多个对象(例如，衬衫上的一个点可能表示衬衫或穿衬衫的人)，输出也应该是这些对象中至少一个的合理掩码。

我们使用提示分割任务作为预训练目标，并通过提示工程解决一般下游分割任务。

## Model 
可提示的分割任务和实际使用的目标对模型架构施加了约束。

特别地，该模型必须支持灵活的提示，需要实时平摊计算掩码以允许动态使用，并且必须具有歧义意识。

令人惊讶的是，我们发现一个简单的设计满足所有三个约束:一个强大的图像编码器计算图像嵌入，一个提示编码器嵌入提示，然后这两个信息源结合在一个轻量级的掩码解码器中，预测分割掩码。

我们把这个模型称为分段任意模型(Segment Anything model)，或SAM(见图1b)。

![image](https://user-images.githubusercontent.com/48575896/230816809-3b0db46d-1b79-4457-a532-493617c919ea.png)

通过将SAM分离为图像编码器和快速提示编码器/掩码解码器，可以使用不同的提示重用相同的图像嵌入(及其成本摊销)。

给定图像嵌入，提示编码器和掩码解码器在网络浏览器中从提示符中预测掩码，时间为~ 50ms。

我们主要关注点、框和掩码提示，并使用自由形式的文本提示来呈现初始结果。

为了使SAM能够感知歧义，我们将其设计为为单个提示预测多个掩码，允许SAM自然地处理歧义，例如衬衫vs.人的示例。

## Data engine
为了实现对新数据分布的强泛化，我们发现有必要在一个大而多样的掩码集上训练SAM，而不是现有的任何分割数据集。

虽然基础模型的典型方法是在线获取数据[82]，但掩码自然并不丰富，因此我们需要一种替代策略。

我们的解决方案是构建一个“数据引擎”，即我们与模型在循环数据集和符号共同开发我们的模型(见图1c)。

![image](https://user-images.githubusercontent.com/48575896/230816845-c13e548f-26f7-4795-ba47-a521e981b2b0.png)

我们的数据引擎有三个阶段:辅助手动、半自动和全自动。

在第一阶段，SAM帮助注释者注释掩码，类似于经典的交互式分割设置。

在第二阶段，SAM可以通过提示可能的对象位置来自动为对象子集生成掩码，而注释器则专注于注释剩余的对象，这有助于增加掩码多样性。

在最后阶段，我们用前景点的规则网格提示SAM，平均每张图像产生约100个高质量蒙版。

## Dataset 
我们最后的数据集SA-1B包含了超过1B掩码来自11M个许可和隐私保护图像(见图2)。

![image](https://user-images.githubusercontent.com/48575896/230817884-8b8483c6-8373-4ab0-a391-e28663772b5d.png)

除了用于训练SAM的健壮性和通用性之外，我们希望SA-1B能够成为一种有价值的资源，用于建立新的基础模型。

## Responsible AI
在使用SA-1B和SAM时，我们研究并报告潜在的公平性问题和偏差。

SA-1B中的图像跨越了地理和经济上不同的国家，我们发现SAM在不同人群中表现相似。

总之，我们希望这将使我们的工作在现实用例中更加公平。

我们在附录中提供了模型和数据集卡。

## Experiments
我们广泛地评估SAM。

首先，我们采用23个分割数据集的多样化新套件，我们发现SAM从单个前景点生成高质量的掩模，通常仅略低于人工注释的地面真相。

其次，我们在使用提示工程的零镜头传输协议下的各种下游任务上发现了始终强大的定量和定性结果，包括边缘检测、对象提议生成、实例分割和文本到掩码预测的初步探索。

这些结果表明，SAM可以与即时工程一起使用，以解决涉及SAM训练数据之外的对象和图像分布的各种任务。

尽管如此，正如我们在§8中讨论的，改进的空间仍然存在。

# Segment Anything Task
我们从NLP中获得灵感，其中下一个令牌预测任务用于基础模型预训练，并通过提示工程师[10]解决各种下游任务。

为了建立一个分割的基础模型，我们的目标是定义一个具有类似功能的任务。

## Task
我们首先将提示的思想从NLP转换为分割，在分割中提示可以是一组前景/背景点，一个粗略的框或蒙版，自由形式的文本，或者，一般来说，任何表明在图像中分割什么的信息。

那么，提示分割任务是在给定任何提示时返回一个有效的分割掩码。

“有效”掩码的要求仅仅意味着即使提示符是模糊的，并且可以引用多个对象(例如，回想一下衬衫vs.人的例子，见图3)，输出应该是这些对象中至少一个的合理掩码。

![image](https://user-images.githubusercontent.com/48575896/230819431-74dab0bb-1b8c-4a39-8bfa-9b34155bf6a0.png)

这一需求类似于期望语言模型对模棱两可的提示符输出一致的响应。

我们选择这个任务是因为它导致了一个自然的预训练算法和一个通过提示将零镜头转移到下游分割任务的通用方法.

## Pre-training
提示分割任务提出了一种自然的预训练算法，该算法为每个训练样本模拟一系列提示(例如，点、框、掩码)，并将模型的掩码预测与地面真相进行比较。

我们从交互式分割[109,70]中采用了这种方法，尽管与交互式分割的目标是在足够的用户输入后最终预测有效掩码不同，我们的目标是始终预测任何提示的有效掩码，即使提示是模糊的。

这确保了预训练的模型在涉及歧义的用例中是有效的，包括我们的数据引擎§4所要求的自动注释。

我们注意到，在这项任务中表现良好具有挑战性，需要专门的建模和训练损失选择，我们将在§3中讨论。

## Zero-shot transfer
直观地说，我们的预训练任务赋予模型在推理时对任何提示作出适当响应的能力，因此可以通过设计适当的提示来解决下游任务。

例如，如果有一个猫的边界盒检测器，猫实例分割可以通过提供检测器的盒子输出作为我们模式的提示来解决.

一般来说，大量的实际分割任务都可以作为提示。

除了自动数据集标记之外，我们还在§7的实验中探索了五个不同的示例任务。

## Related tasks.
分割是一个广泛的领域:有动态分割[57,109]、边缘检测[3]、素像素化[85]、目标提议生成[2]、前景分割[94]、语义分割[90]、原地分割[66]、全景分割[59]等。

我们的提示分割任务的目标是产生一个广泛的能力模型，可以适应许多(虽然不是全部)现有的和新的分割任务通过提示工程。

这种能力是任务概括的一种形式[26]。

注意，这与以前的多任务分割系统不同。

在多任务系统中，单个模型执行一组固定的任务，例如联合语义、实例和全景分割[114,19,54]，但训练和测试任务是相同的。

在我们的工作中，一个重要的区别是，为提示分割训练的模型可以在推理时作为一个更大的系统中的组件执行一个新的、不同的任务，例如，为了执行实例分割，提示分割模型与现有的对象检测器相结合。

## Discussion
提示和组合是强大的工具，可以以可扩展的方式使用单个模型，有可能完成模型设计时未知的任务。

这种方法类似于其他基础模型的使用方式，例如CLIP[82]是DALL·E[83]图像生成系统的文本图像对齐组件。

我们预计，由提示工程等技术驱动的可组合系统设计，将比专门为一组固定任务训练的系统能够实现更广泛的应用。

通过组成的镜头来比较提示分割和交互式分割也是有趣的:虽然交互式分割模型是在设计时考虑到人类用户，但为提示分割训练的模型也可以组成一个更大的算法系统，正如我们将演示的那样。

# Segment Anything Model
接下来我们描述分段任意模型(SAM)用于提示分段。

SAM有三个组成部分，如图4所示:一个图像编码器，一个灵活的提示编码器和一个快速的掩码解码器。

我们建立在Transformer视觉模型[14,33,20,62]的基础上，为(平摊)实时性能。

我们在这里对这些组件进行高层次的描述，详细内容见§a。

![image](https://user-images.githubusercontent.com/48575896/230822655-2afda656-c8f8-46cc-8218-8ec6ff387654.png)

## Image encoder
由于可扩展性和强大的预训练方法，我们使用MAE[47]预训练视觉变压器(ViT)[33]最小限度地适应于处理高分辨率输入[62]。

图像编码器对每张图像运行一次，可以在提示模型之前应用.

## Prompt encoder
我们考虑两组提示:稀疏提示(点、框、文本)和密集(蒙版)。

我们通过位置编码[95]表示点和框，并对每种提示类型和自由形式的文本使用CLIP现成的文本编码器[82]进行学习嵌入。

密集提示(即掩码)使用卷积嵌入，并与图像嵌入元素相加。

## Mask decoder
