# 大型语言模型综述全新出炉：从T5到GPT-4最全盘点，国内20余位研究者联合撰写
大型语言模型综述全新出炉：从T5到GPT-4最全盘点，国内20余位研究者联合撰写

自 20 世纪 50 年代图灵测试提出以来，人们始终在探索机器处理语言智能的能力。

语言本质上是一个错综复杂的人类表达系统，受到语法规则的约束。

因此，开发能够理解和精通语言的强大 AI 算法面临着巨大挑战。

过去二十年，语言建模方法被广泛用于语言理解和生成，包括统计语言模型和神经语言模型。

近些年，研究人员通过在大规模语料库上预训练 Transformer 模型产生了预训练语言模型（PLMs），并在解决各类 NLP 任务上展现出了强大的能力。

并且研究人员发现模型缩放可以带来性能提升，因此他们通过将模型规模增大进一步研究缩放的效果。

有趣的是，当参数规模超过一定水平时，这个更大的语言模型实现了显著的性能提升，并出现了小模型中不存在的能力，比如上下文学习。

为了区别于 PLM，这类模型被称为大型语言模型（LLMs）。

从 2019 年的谷歌 T5 到 OpenAI GPT 系列，参数量爆炸的大模型不断涌现。

可以说，LLMs 的研究在学界和业界都得到了很大的推进，尤其去年 11 月底对话大模型 ChatGPT 的出现更是引起了社会各界的广泛关注。

LLMs 的技术进展对整个 AI 社区产生了重要影响，并将彻底改变人们开发和使用 AI 算法的方式。

考虑到 LLMs 的快速技术进步，中国人民大学的二十几位研究者通过背景知识、关键发现和主流技术等三方面回顾了 LLMs 的最新进展，尤其关注 LLMs 的预训练、自适应调优、使用和能力评估。

此外他们还总结和开发 LLMs 的可用资源，讨论了未来发展方向等问题。对于领域内研究人员和工程师而言，这份综述是一份极其有用的学习资源。

![image](https://user-images.githubusercontent.com/48575896/229475367-231b5cfb-f042-4982-8279-94aa61921eb3.png)

论文链接：https://arxiv.org/abs/2303.18223

在进入正文前，我们先来看 2019 年以来出现的各种大语言模型（百亿参数以上）时间轴，其中标黄的大模型已开源。

![image](https://user-images.githubusercontent.com/48575896/229475469-4b5efdee-b155-4ae0-82f1-77f4d8cb3964.png)


# LLMs 概览
在第一节中，研究者详细介绍了 LLMs 的背景、能力和关键技术。

## LLMs 的背景
通常，大型语言模型（LLM）是指包含数千亿（或更多）参数的语言模型，这些参数是在大量文本数据上训练的，例如模型 GPT-3、PaLM、Galactica 和 LLaMA。

具体来说，LLM 建立在 Transformer 架构之上，其中多头注意力层堆叠在一个非常深的神经网络中。

现有的 LLM 主要采用与小语言模型类似的模型架构（即 Transformer）和预训练目标（即语言建模）。

作为主要区别，LLM 在很大程度上扩展了模型大小、预训练数据和总计算量（扩大倍数）。

他们可以更好地理解自然语言，并根据给定的上下文（例如 prompt）生成高质量的文本。

这种容量改进可以用标度律进行部分地描述，其中性能大致遵循模型大小的大幅增加而增加。

然而根据标度律，某些能力（例如，上下文学习）是不可预测的，只有当模型大小超过某个水平时才能观察到。

## LLMs 的涌现能力
LLM 的涌现能力被正式定义为「在小型模型中不存在但在大型模型中出现的能力」，这是 LLM 与以前的 PLM 区分开来的最显著特征之一。

当出现这种新的能力时，它还引入了一个显著的特征：当规模达到一定水平时，性能显著高于随机的状态。

以此类推，这种新模式与物理学中的相变现象密切相关。

原则上，这种能力也可以与一些复杂的任务有关，而人们更关心可以应用于解决多个任务的通用能力。

这里简要介绍了 LLM 的三种代表性的涌现能力：

### 上下文学习。
GPT-3 正式引入了上下文学习能力：假设语言模型已经提供了自然语言指令和多个任务描述，它可以通过完成输入文本的词序列来生成测试实例的预期输出，而无需额外的训练或梯度更新。

### 指令遵循。
通过对自然语言描述（即指令）格式化的多任务数据集的混合进行微调，LLM 在微小的任务上表现良好，这些任务也以指令的形式所描述。

这种能力下，指令调优使 LLM 能够在不使用显式样本的情况下通过理解任务指令来执行新任务，这可以大大提高泛化能力。

### 循序渐进的推理。
对于小语言模型，通常很难解决涉及多个推理步骤的复杂任务，例如数学学科单词问题。

同时，通过思维链推理策略，LLM 可以通过利用涉及中间推理步骤的 prompt 机制来解决此类任务得出最终答案。

据推测，这种能力可能是通过代码训练获得的。

## 关键技术
接下来来看 LLMs 的关键技术，包括了缩放、训练、能力激发、对齐调优、工具利用等。

### 缩放。
缩放是增加 LLMs 模型容量的关键因素，最开始 GPT-3 将模型参数增至 1750 亿，随后 PaLM 进一步将模型参数增至 5400 亿。

大规模参数对于涌现能力至关重要。缩放不仅针对模型大小，还与数据大小和总计算量有关。

### 训练。
由于规模巨大，成功训练一个具备强大能力的 LLMs 非常具有挑战性。

因此需要分布式训练算法来学习 LLMs 的网络参数，经常联合使用各种并行策略。

为了支持分布式训练，DeepSpeed 和 Megatron-LM 等优化框架被用来促进并行算法的实现和部署。

此外，优化技巧对训练稳定性和模型性能也很重要，例如重新启动训练损失尖峰和混合精度训练。

最近的 GPT-4 开发了特殊的基础设施和优化方法，从而利用小得多的模型来预测大模型的性能。

### 能力激发。
在大规模语料库上经过预训练后，LLMs 被赋予了解决一般任务的潜在能力。

然而当 LLMs 执行某个特定任务时，这些能力可能不会显式地表现出来。

因此设计适合的任务指令或特定的上下文策略来激发这些能力非常有用，比如思维链 prompt 有助于通过中间推理步骤等解决复杂推理任务。

此外还可以进一步对具有自然语言任务描述的 LLMs 进行指令调优，以提高对未见过任务的泛化能力。

### 对齐调优。
由于 LLMs 被训练用来捕获预训练语料库的数据特征（包括高质量和低质量的数据），它们很可能生成对有毒、有偏见和有害的文本内容。

为了使 LLMs 与人类价值观保持一致，InstructGPT 设计了一种利用强化学习和人类反馈的高效调优方法，使得 LLMs 能够遵循预期指令。

ChatGPT 是在类似 InstructGPT 的技术上开发的，在产生高质量、无害的响应方面表现出了强大的对齐能力。

### 工具利用。
LLMs 本质上是基于大规模纯文本语料库训练的文本生成器，因此在数值计算等文本表达不佳的任务上表现没那么好。

此外 LLMs 的能力受限于预训练数据，无法捕获最新信息。

针对这些问题，人们提出使用外部工具来弥补 LLMs 的不足，比如可以利用计算器进行精确计算，使用搜索引擎检索未知信息。

针对这些问题，人们提出使用外部工具来弥补 LLMs 的不足，比如可以利用计算器进行精确计算，使用搜索引擎检索未知信息。

# 预训练
预训练建立了 LLMs 的能力基础。

通过对大规模语料库的预训练，LLMs 可以获得基本的语言理解和生成技能。

在这个过程中，预训练语料库的规模和质量是 LLMs 获得强大能力的关键。

此外，为了有效地预训练 LLMs，模型架构、加速方法和优化技术都需要精心设计。

在第四节中，研究者首先在第 4.1 节讨论了数据的收集和处理，然后在第 4.2 节介绍了常用的模型架构，最后在第 4.3 节介绍了稳定和有效优化 LLMs 的训练技术。
