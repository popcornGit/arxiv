# LiDARFormer：LiDAR检测&分割统一多任务网络（图森）
# 摘要
最近激光雷达感知领域出现了一种趋势，即将多个任务统一在一个强大的网络中，从而提高性能，而不是为每个任务使用单独的网络。

本文介绍了一种新的基于Transformer的激光雷达多任务学习范式。

所提出的LiDARFormer利用跨空间全局上下文特征信息，并利用跨任务协同作用，在多个大规模数据集和基准上提高LiDAR感知任务的性能。

论文新颖的基于Transformer的框架包括跨空间Transformer模块，该模块学习2D密集鸟瞰图（BEV）和3D稀疏体素特征图之间的注意力特征。

此外，论文提出了一种用于分割任务的Transformer解码器，通过利用分类特征表示来动态调整学习的特征。

此外将共享Transformer解码器中的分割和检测特征与跨任务注意力层相结合，以增强和集成目标级和类级特征。

LiDARFormer在大规模nuScenes和Waymo Open数据集上进行了3D检测和语义分割任务的评估，并且在这两项任务上都优于所有先前发表的方法。

值得注意的是，对于单模型LiDAR方法，在具有挑战性的Waymo和nuScenes检测基准上，LiDARFormer实现了76.4%L2 mAPH和74.3%NDS的最新性能。

总结来说，本文的主要贡献如下：

1.在多任务网络中，当在稀疏体素特征和密集边界元特征之间转移特征时，论文提出了一个跨空间Transformer模块来改进特征学习；

2.论文提出了第一个LiDAR跨任务Transformer解码器，该解码器将学习到的信息跨目标级和类级特征嵌入进行桥接；

3.论文介绍了一种基于Transformer的粗到细网络，该网络利用Transformer解码器为激光雷达语义分割任务提取类级全局上下文信息；

4.论文在两个流行的大规模激光雷达基准上实现了最先进的3D检测和语义分割性能。

# 方法
本节将介绍激光LiDARFormer的设计。

如图2所示，框架由三部分组成：

1.使用3D稀疏卷积的3D编码器-解码器骨干网络；

2.一种跨空间Transformer（XSF）模块，用于提取BEV中的大规模和上下文特征；

3.一种跨任务Transformer（XTF）解码器，其从体素和BEV特征图聚合类和对象全局上下文信息。

本文的网络采用了LidarMultiNet[62]的多任务学习框架，但通过共享的跨任务注意力层进一步将分割和检测之间的全局特征相关联。

![image](https://user-images.githubusercontent.com/48575896/229677314-29d06085-7c02-46d9-94d3-1460959a9258.png)

## 基于体素的LiDAR感知
### 体素化：

首先将点云坐标转换为体素索引。

然后使用一个简单的体素特征编码器，它只包含多层感知器（MLP）和最大池化层来生成稀疏体素特征表示：

$$ \mathcal{V}_{j}=\max _{\mathcal{I}_{i}=\mathcal{I}_{j}}\left(\operatorname{MLP}\left(p_{i}\right)\right), j \in(1 \ldots M)$$

### 基于稀疏体素的骨干网络：
使用VoxelNet[73]作为网络的骨干，其中体素特征在编码器中逐渐下采样到原始大小的1/8。

稀疏体素特征被投影到密集BEV图上，然后是2D多尺度特征提取器来提取全局信息。

对于检测任务，将检测头附加到BEV特征图上，以预测目标边界框。

对于分割任务，BEV特征被重新投影到体素空间，在那里使用U-Net解码器将特征图上采样回原始比例。

论文用体素级标签 $L^v$ 监督论文的模型，并在推理过程中通过去体素化步骤将预测的标签投影回点云层级。

## Cross-space Transformer
![image](https://user-images.githubusercontent.com/48575896/229678962-9698454d-d203-476f-8625-6f5a59820cef.png)

如图1所示，基于体素的激光雷达检测和分割通常需要骨干网络分别在2D密集BEV空间和3D稀疏体素空间上提取特征表示。

为了克服合并从这两个任务中学习到的特征的挑战，先前的多任务网络[62]提出了一个全局上下文池模块，以根据特征的位置直接映射特征，而不考虑稀疏性的差异。

相反，论文提出了一种跨空间转换器模块，该模块利用可变形注意力来增强这些空间之间的特征提取，以进一步增加感受野。

如图2所示，论文使用跨空间Transformer来：

1.将上一个尺度中的稀疏体素特征转换为密集BEV特征（稀疏到密集），

2.将密集BEV特性从2D多尺度特征提取器转换为稀疏体素特性。

跨空间转换器如图3所示。

![image](https://user-images.githubusercontent.com/48575896/229680370-16140eaf-c7aa-48da-8159-aa95d65e2446.png)

![image](https://user-images.githubusercontent.com/48575896/229705002-5a6c4ca3-419a-46a0-b58c-1f298999d7bd.png)

采用可变形注意力[76]作为自注意力层来探索密集特征图中的全局信息。

由于 $F^dense$ 缺乏高度信息，由于2D多尺度特征提取器主要关注BEV级别的信息，论文开发了一个多头多高度注意力模块来学习所有高度的特征：

对于在高度h的切片BEV特征图上位置的每个参考体素，可变形的自注意使用线性层来学习所有头部和高度的BEV偏移。

多高度可变形自注意力的输出可以公式化为：

$$\chi(p)=\sum_{i=1}^{N_{\text {head }}} W_{i}\left[\sum_{j=1}^{N_{\text {height }}} \sum_{r=1}^{R} \sigma\left(W_{i j r} q_{p}\right) W_{i}^{\prime} x^{j}\left(\xi+\Delta \xi_{i j r}\right)\right]$$

由于密集到稀疏交叉空间Transformer是在2D特征提取器之后应用的，它不会影响所学习的2D BEV特征，因此对提高检测性能的影响有限。

为了增加2D BEV特征提取器的感受野，论文添加了一个跨空间转换器模块，以类似的方式转换为密集的BEV特征，如图3b所示。

它为BEV特征提供了更多的上下文信息，BEV特征将被馈送到2D多尺度特征提取器中。

## Cross-task Transformer Decoder
尽管目标检测和语义分割共享相关信息，但它们通常是在两个独立的网络结构中学习的。

LidarMultiNet[62]证明，通过共享中间特征表示，可以提高检测和分割性能。

然而，在多任务网络的训练期间，没有共享高级信息。

为了进一步探索多任务学习的协同作用，论文建议使用共享的转换器解码器来桥接来自分割的类级信息和来自检测的对象级信息。

然后介绍了一种通过跨任务注意力将这种分割解码器与传统的检测解码器连接起来的方法。

### 分割Transformer解码器：
